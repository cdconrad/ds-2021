{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Manaing big(ger) Airbnb data with data frames\n",
    "*Â© 2021 Colin Conrad*\n",
    "\n",
    "Welcome to Week 5 of INFO 6270! Last week we explored how to use _libraries_ to make our lives easier. We then used this skill to import CSV files and JSON data into our Python framework. With this knowledge in hand, you are now ready to start working with data more earnestly. This is the first lab of the second unit, nicknamed _Scrappy Data Science for Managers_. Scrappy, in this context, because we are going to learn data science tools in a seemingly ad-hoc way, in an effort to introduce you tackle common problems that you might experience in your information management or other boradly managerial career.\n",
    "\n",
    "The [Pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) dataframe is a tool which makes it easier to navigate and analyze large datasets. Built upon numpy and other dependencies, this tool is among the most essential resources for conducting analysis on larger datasets. We will also use this tool in nearly all subsequent labs (at least, all labs in Unit 2), so be sure to explore this one closely!\n",
    "\n",
    "**This week, we will achieve the following objectives:**\n",
    "- Turn your dataset into a dataframe and build a simple query\n",
    "- Observe additional features and create an advanced query\n",
    "- Collect descriptive statistics from your dataframe\n",
    "- Make changes to your dataframe\n",
    "\n",
    "Weekly reading: [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case: Airbnb\n",
    "It's pretty likely that you know something about [Airbnb](https://www.airbnb.ca/). Airbnb has been called the [world's largest hotel chain](https://www.bizjournals.com/sanfrancisco/news/2017/08/11/airbnb-surpasses-ihg-wyn-hilton-marriott-listings.html), while owning no hotels themselves. As a crowdsourcing platform, users can list their properties and rent them out to short-term renters using the Airbnb app. Though the company is not yet 13 years old as of January 2021, it has a market valuation of [$113 billion], nearly 13 times the estimated value of Hilton hotel brands (the most valuable hotel chain).\n",
    "\n",
    "Airbnb is not without controversy. Airbnb has been identified by the [Economic Policy Institute](https://www.epi.org/publication/the-economic-costs-and-benefits-of-airbnb-no-reason-for-local-policymakers-to-let-airbnb-bypass-tax-or-regulatory-obligations/) as an important factor in rising rent an property prices, despite often escaping tax and regulation. The company [regularly releases their application data publicly](http://insideairbnb.com/get-the-data.html). Though we cannot investigate this phenomenon in one lab, this is a useful resource for learning about data science tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1: Turn your dataset into a dataframe and build a simple query\n",
    "As discussed in class, pandas is a framework built on top of the numpy library designed to make data science easier. Numpy is a tool for transforming your data into a multi-dimensional array, sort of like a hyper-efficient Python list. It's not great to use unless you are interested in going deep into machine learning. The pandas (PANel + DAta) library transforms our data into numerical tables (a.k.a. data frames) which are easier to calculate and sort through. We will start with Pandas because this is the tool that will be most useful for us.\n",
    "\n",
    "To transform a csv file into a pandas object we need to import the pandas library. We can then import a csv file by using pandas' built-in read_csv feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # import pandas \n",
    "\n",
    "import numpy as np # import numpy; it's usually a good practice to import this as well\n",
    "\n",
    "nyc = pd.read_csv('data/w5_nyc.csv') # command pandas to import the data; isn't this easier than the csv library?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe head\n",
    "Once our data frame has been imported we can apply a few methods that can generate knowledge about the dataset. The `head()` method gives us a summary of the first five items in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe series\n",
    "\n",
    "Data frames are easily navigable compared to lists or dictionaries. If we want to retrieve all of the data from a column in the dataframe, we can call that column similarly to calling a method. The code below will give us the values for `neighbourhood_group` from the whole dataset, but will give us only the first and last values when printed. This is super-handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.neighbourhood_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A transposed dataframe\n",
    "\n",
    "Some things that are somewhat cumbersome with lists and dictionaries are also very simple with pandas. For instance, if we wish to transpose our data (make the rows columns and the columns rows) we can use the `.T` method. This can be helpful when making calculations across entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort values\n",
    "In addition, dataframes can be easily sorted. These sorting features are similar to SQL (_Structured Query Language_) which many of you will be familiar with (and will cover in Week 10). The following code will sort the data by price starting with the highest values. \n",
    "\n",
    "I wonder who seriously believes that they can rent an apartment for $10 000 per night?! It must be fancy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.sort_values(by='last_review', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 1 (0.5 points)*\n",
    "Using the `sort` function on the `nyc` dataframe, conduct a query that can be used to discover which listing has the highest `reviews_per_month`. Provide a comment which indicates your opinion about whether this value is an anomoly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 2 (0.5 points)*\n",
    "Using the `nyc` dataframe, conduct a simple query to retrieve the last five rows in the dataframe. There is a pandas method to do this-- be sure to read _10 minutes to pandas_ to learn more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 2: Observe additional features and create an advanced query\n",
    "## Subsetting the data\n",
    "Dataframes are for a lot more than performing large observations. Perhaps the coolest feature of a dataframe is that it facilitates efficient queries and to retrieve subsets of the data. In pandas, a subset is declared by writing square brackets following the data frame-- for instance, `nyc['neighbourhood_group']` would return the values of neighborhood. However, we can also use this to conduct Boolean searches as well. For instance, if we wanted to retrieve only the values where `neighbourhood_group == Brooklyn` we could write a query as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc[nyc.neighbourhood_group == 'Brooklyn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting subsets\n",
    "\n",
    "Similarly, to before, if we wanted to list the values from Brooklyn according to price, we can create a new data frame which is equal to this subset and sort it by price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = nyc[nyc.neighbourhood_group == 'Brooklyn']\n",
    "\n",
    "brooklyn.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by date-time\n",
    "Pretty cool! Another feature of pandas is that it recognizes common data types which are not recognized as distinct types by Python itself. For example, pandas dataframes are optimized to recognize date and time formats. If we want to sort a search by `last_review`, for instance, we could conduct a similar query as with `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_brooklyn = nyc[(nyc.neighbourhood_group == 'Brooklyn')]\n",
    "\n",
    "recent_brooklyn.sort_values(by='last_review', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query using two conditions\n",
    "\n",
    "Queries can also be more complex. If we wish to choose a subset of data which is constrained by two conditions, we can include both conditions by using the `&` operator. The following query will retrieve the values that match `Brooklyn` which also have a `last_review` equal to `2019-08-06`, the date that I seem to have retrieved this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_brooklyn = nyc[(nyc.neighbourhood_group == 'Brooklyn') & \n",
    "                      (nyc.last_review == '2019-08-06')]\n",
    "\n",
    "recent_brooklyn.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying using two conditions, one of which is an OR\n",
    "\n",
    "Finally, we can also create nested queries. The following query searches for values which match `Brooklyn` but have a last_review in the two days prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_brooklyn = nyc[(nyc.neighbourhood_group == 'Brooklyn') & \n",
    "                      ((nyc.last_review == '2019-08-06') | (nyc.last_review == '2019-08-05'))]\n",
    "\n",
    "recent_brooklyn.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 3 (1 point)*\n",
    "Using the `nyc` dataframe, conduct a query which retrieves the following:\n",
    "- Rentals only from the `Queens` neighborhood\n",
    "- Rentals with either more than 100 reviews or more than 5 reviews per month\n",
    "- Rentals with a price of less than 200\n",
    "- Rentals which are the `Entire home/apt` room type\n",
    "\n",
    "Sort your findings by order of price, starting with the lowest price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 2: Collect descriptive statistics from your dataframe\n",
    "One of the most handy features of pandas dataframes is that they come with a few built-in methods for conducting descriptive analysis. For example, the `.describe()` method will give summary of statistical measures of a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe a column\n",
    "This is good, but perhaps too much to be useful. Instead, we could choose to apply `.describe()` to a single column. This will give us more manageable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean price\n",
    "In addition, dataframes also have functions for calculating specific statistics such as mean, median and mode. To calculate the mean value of a column we can write the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the sum\n",
    "Alternatively, if we wanted to find the sum of a column (e.g. the total number of reviews) we can use the sum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.number_of_reviews.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number of unique values\n",
    "Finally, there are a few other methods which are handy. For instance, the `.nunique()` method will tell use the number of unique values in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.host_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 4 (1 point)*\n",
    "Write code that calculates the median price for the property category of `'Entire home/apt'`. \n",
    "\n",
    "**Hint**: [This tutorial site](https://www.tutorialspoint.com/python_pandas/python_pandas_descriptive_statistics.htm) has a pretty good summary of dataframe functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 5 (0.5 points)*\n",
    "Write code which finds the neighborhood (*not* neighbourhood_group) with the most listings. You can probably do this in one line, though if you choose to use a more complex function, you are welcome to do so! \n",
    "\n",
    "**Hint:** Consider reviewing the standard descriptive statistics: mean, median and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 6 (0.5 points)*\n",
    "The `availability_365` column represents the number of days in the past year that the property was available to rent through the Airbnb app. Retrieve the number of listings in New York which were available every day of the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 4: Make changes to your dataframe\n",
    "In addition to being navigable, dataframes are also relatively easy to change. For instance, if we wanted to insert a column, we could use the `.insert()` method. According to the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.insert.html), this method requires four pieces of information: \n",
    "- Where to insert it\n",
    "- The name of the column\n",
    "- The value to be inserted\n",
    "- Whether to allow duplicates\n",
    "\n",
    "The code below inserts the value \"Airbnb\" in a column named `dataset`. This would be handy if we acquired our data from more than one source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.insert(2, \"dataset\", \"Airbnb\", True)\n",
    "nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting data in python\n",
    "This said, given that our data came from a single source, we have no need for this. To drop a column, we could choose to use the del keyword, which deletes objects stored in python. Note that this keyword is not unique to pandas and can be used for virtually anything in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nyc['dataset']\n",
    "nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The drop method\n",
    "The proper way to drop a column in pandas however is to use the `.drop()` method. This method is used to drop rows or columns from a pandas dataframe. For instance, if we wished to drop the first entry we could use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nyc = nyc.drop([0, 1]) # create a new dataframe which has the first two values dropped\n",
    "\n",
    "mod_nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas drops rows by default so we only needed to provide the indexes to make it happen. Alternatively, to drop columns we need to provide a label and an `axis=1` value to tell pandas to search for the column with said label. If we wished to remove the host names (say, in order to better preserve privacy) we could specify the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nyc = nyc.drop(labels='host_name', axis=1) # create a new dataframe which has the first two values dropped\n",
    "\n",
    "mod_nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering new columns\n",
    "We can also add new columns to our dataframe. To create a new column, you can add the column values using a key/value format. The code below creates a new column called `reviews_to_avaliability_ratio` which calculates the number of reviews relative to the listing availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc['reviews_to_avaliability_ratio'] = nyc['number_of_reviews']/nyc['availability_365']\n",
    "\n",
    "nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Challenge Question 7 (1 point)*\n",
    "One measure which might be interesting in this dataset is the ratio of price to number of reviews. Create a new column called `price_to_review_ratio` which calculates the price divided by the reviews. Once you have added this column, provide code which prints the median value of this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
